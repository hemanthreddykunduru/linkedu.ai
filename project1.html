<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ShortGPT Model</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);
            background-size: 400% 400%;
            animation: gradient 15s ease infinite;
            min-height: 100vh;
            color: white;
        }
        
        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            padding: 10px 20px;
            font-size: 16px;
            font-weight: bold;
            color: white;
            background: rgba(0, 0, 0, 0.5);
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: transform 0.3s ease, background 0.3s ease;
            z-index: 1000;
        }
        
        .back-button:hover {
            transform: scale(1.1);
            background: rgba(0, 0, 0, 0.8);
        }
        
        .header {
            text-align: center;
            padding: 60px 0;
            animation: fadeIn 1s ease-out;
        }
        
        .header h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .header p {
            font-size: 1.2em;
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            padding: 40px 0;
        }
        
        .feature-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 30px;
            border-radius: 15px;
            transition: transform 0.3s ease;
            animation: fadeIn 1s ease-out;
        }
        
        .feature-card:hover {
            transform: translateY(-10px);
        }
        
        .feature-card h3 {
            margin-bottom: 15px;
            font-size: 1.5em;
        }
        
        .architecture-section {
            padding: 40px 0;
        }
        
        .architecture-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 30px;
            margin: 30px 0;
        }
        
        .architecture-image {
            width: 100%;
            height: 200px;
            object-fit: cover;
            border-radius: 10px;
            cursor: pointer;
            transition: transform 0.3s ease;
        }
        
        .architecture-image:hover {
            transform: scale(1.05);
        }
        
        .download-section {
            text-align: center;
            padding: 60px 0;
        }
        @keyframes dropdown-gradient {
            0% { background-position: 100% 50%; }
            50% { background-position: 0% 50%; }
            100% { background-position: 100% 50%; }
        }
        .download-button {
            display: inline-block;
            padding: 15px 40px;
            font-size: 1.2em;
            font-weight: bold;
            color: none;
            background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);
            border: none;
            border-radius: 10px;
            cursor: pointer;
            text-decoration: none;
            align-items: center;
            transition: background 0s ease;
            background-size: 200% 200%;


            animation: dropdown-gradient 15s ease infinite;
        }

        .download-button:hover {
            transform: scale(1.05);
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        }
        
        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.9);
            z-index: 1001;
            overflow: auto;
            animation: fadeIn 0.3s ease-out;
        }

        .modal-content {
            margin: auto;
            display: block;
            max-width: 90%;
            max-height: 90vh;
            margin-top: 50px;
        }
        
        .close {
            position: fixed;
            top: 15px;
            right: 35px;
            color: #f1f1f1;
            font-size: 40px;
            font-weight: bold;
            cursor: pointer;
            transition: color 0.3s ease;
        }
        
        .close:hover {
            color: #e73c7e;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @keyframes zoomIn {
            from { transform: scale(0.9); opacity: 0; }
            to { transform: scale(1); opacity: 1; }
        }

        .modal-content {
            animation: zoomIn 0.3s ease-out;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            background: transparent;
            backdrop-filter: blur(10px);
        }
        th, td {
            border: 1px solid rgba(255, 255, 255, 0.2);
            padding: 14px;
            text-align: left;
            color: #ddd;
        }
        th {
            background-color: rgba(0, 123, 255, 0.2);
            color: #fff;
            font-size: 16px;
        }
        tr:nth-child(even) {
            background-color: rgba(255, 255, 255, 0.1);
        }
        tr:hover {
            background-color: rgba(255, 255, 255, 0.2);
            transition: 0.3s ease-in-out;
        }
        
        /* Dropdown Styles */
        .dropdown {
            margin: 20px 0;
            position: relative;
        }
        /*Toggle for the without rag */
        @keyframes dropdown-gradient {
            0% { background-position: 100% 50%; }
            50% { background-position: 0% 50%; }
            100% { background-position: 100% 50%; }
        }
        .dropdown-toggle {
            background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);
            width: 100%;
            padding: 15px 20px;
            font-size: 1.5em;
            font-weight: bold;
            color: none;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            text-align: left;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: background 0s ease;
            
            /* Apply animation */
            background-size: 200% 200%;
            animation: dropdown-gradient 15s ease infinite;
        }
        
        
        .dropdown-toggle:hover {
            background: linear-gradient(45deg, #1e95c0, #1eb995);
        }
        
        .dropdown-toggle::after {
            content: '‚ñº';
            font-size: 0.8em;
            margin-left: 10px;
            transition: transform 0.3s ease;
        }
        
        .dropdown-toggle.active::after {
            transform: rotate(180deg);
        }
        /*Toggle for the with rag */
        .dropdown-toggle.with-rag {
            background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab);
            width: 100%;
            padding: 15px 20px;
            font-size: 1.5em;
            font-weight: bold;
            color: none;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            text-align: left;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: background 0s ease;
            
            /* Apply animation */
            background-size: 200% 200%;
            animation: dropdown-gradient 15s ease infinite;
        }
        
        .dropdown-toggle.with-rag:hover {
            background: linear-gradient(45deg, #1e95c0, #1eb995);
        }
        
        .dropdown-toggle.with-rag::after {
            content: '‚ñº';
            font-size: 0.8em;
            margin-left: 10px;
            transition: transform 0.3s ease;
        }
        
        .dropdown-toggle.with-rag.active::after {
            transform: rotate(180deg);
        }
        
        .dropdown-content {
            display: none;
            background: transparent;
            backdrop-filter: blur(10px);
            border-radius: 0 0 10px 10px;
            padding: 20px;
            animation: fadeIn 0.5s ease-out;
            margin-top: 5px;
        }
        
        .dropdown-content.show {
            display: block;
        }

    </style>
</head>
<body>
    <button class="back-button" onclick="history.back()">üîô</button>
    
    <!-- Modal -->
    <div id="imageModal" class="modal">
        <span class="close">&times;</span>
        <img class="modal-content" id="modalImage">
    </div>

    <div class="container">
        <header class="header">
            <h1>ShortGPT Model</h1>
            <p>Your personal, locally-run LLM. Train it on your own PDFs or Any source and watch it become an expert on your knowledge.</p>
        </header>

        <!-- Without RAG Dropdown Section -->
        <div class="dropdown">
            <button class="dropdown-toggle" onclick="toggleDropdown('withoutRagContent', this)">Without RAG</button>
            <div class="dropdown-content" id="withoutRagContent">
                <!-- All content from the original page goes here -->
                <header class="header">
                    <p>Your personal, locally-run LLM. Train it on your own PDFs or Any source and watch it become an expert on your knowledge. Unlike other models, ShortGPT retains all previously learned information. Every time you add new documents and retrain, it simply expands its understanding ‚Äì never forgetting what it learned before. Get accurate, consistent results, tailored to your specific needs.</p>
                </header>

                <section class="features">
                    <div class="feature-card">
                        <h3>Custom Training</h3>
                        <p>Train the model with your specific knowledge like (pdf,txt) and get responses from model.</p>
                    </div>
                    <div class="feature-card">
                        <h3>Hardware Support</h3>
                        <p>Optimized for both GPU and CPU environments, providing flexible deployment options.</p>
                    </div>
                    <div class="feature-card">
                        <h3>Advanced Architecture</h3>
                        <p>Built with custom transformers, attention layers, and positional encoders for optimal performance.</p>
                    </div>
                    <div class="feature-card">
                        <h3>My Training</h3>
                        <ul>
                            <li>Trained on 1,930,119 characters</li>
                            <li>Trained over 10 epochs</li>
                            <li>Trained for 17 hrs 9 min 30 sec</li>
                        </ul>
                    </div>
                    <div class="feature-card">
                        <h3>My System configuration</h3>
                        <ul>
                            <li>CPU: Intel Core i7(12th gen)</li>
                            <li>GPU: NVIDIA RTX3050 Laptop(4GB GDDR6)</li>
                            <li>RAM: 16GB DDR4</li>
                        </ul>
                    </div>
                </section>
                <h2>What were the criteria for choosing this algorithm‚ùì</h2>
                <br>
                <table>
                    <tr>
                        <th>Algorithm</th>
                        <th>Description</th>
                        <th>Benefit</th>
                    </tr>
                    <tr>
                        <td><b>Transformer</b></td>
                        <td>Replaces RNNs with self-attention</td>
                        <td>Fast parallel processing</td>
                    </tr>
                    <tr>
                        <td><b>Multi-Head Self-Attention (8 heads)</b></td>
                        <td>Learns multiple relationships in parallel</td>
                        <td>Improves context understanding</td>
                    </tr>
                    <tr>
                        <td><b>512-Dimension Embeddings</b></td>
                        <td>Represents tokens with high-dimensional vectors</td>
                        <td>Captures complex meanings</td>
                    </tr>
                    <tr>
                        <td><b>2048-Dimension Feed-Forward Layer</b></td>
                        <td>Expands and compresses attention output</td>
                        <td>Enhances feature extraction</td>
                    </tr>
                    <tr>
                        <td><b>Word-Level Tokenization</b></td>
                        <td>Uses full words instead of subwords</td>
                        <td>Simplifies processing, useful for short texts</td>
                    </tr>
                    <tr>
                        <td><b>Frequency-Based Vocabulary Truncation</b></td>
                        <td>Keeps only high-frequency words</td>
                        <td>Reduces memory usage and speeds up inference</td>
                    </tr>
                </table>
                <section class="architecture-section">
                    <h2>Model Architecture</h2>
                    <div class="architecture-grid">
                        <img src="./images/project1/complete.png" class="architecture-image" alt="complete workflow architecture" onclick="openModal(this)">
                        <img src="./images/project1/transformers_Arc.png" class="architecture-image" alt="transformers_architecture" onclick="openModal(this)">
                        <img src="./images/project1/2.png" class="architecture-image" alt="work flow diagram" onclick="openModal(this)">
                        <img src="./images/project1/1.png" class="architecture-image" alt="complete work flow" onclick="openModal(this)">
                        <img src="./images/project1/complete1.png" class="architecture-image" alt="diagram" onclick="openModal(this)">
                    </div>
                </section>

                <img src="./images/project1/transformers_example.png" class="architecture-image" alt="explaining with example" onclick="openModal(this)">
                
                <section class="architecture-section">
                    <h2>Training Status & Result</h2>
                    <div class="architecture-grid">
                        <img src="./images/project1/training result.png" class="architecture-image" alt="training results image" onclick="openModal(this)" alt="Training Results">
                        <img src="./images/project1/compiler output.png" class="architecture-image" alt="compiler output image" onclick="openModal(this)" alt="Compiler Output">
                    </div>
                </section>
                
                <h3>" My model is trained with fewer parameters compared to ChatGPT or LLaMA. However, I plan to continue training it whenever I have access to a GPU. "</h3>
                <h3>Stay tuned__you should definitely try my model! I'm also working on refining its grammar and accuracy for even better performance.</h3>
                <br>
                <h3>" I'm working on the final touches for the model and are looking forward to releasing it soon! Stay tuned for updates in the coming days, and we appreciate your patience. "</h3>
                <section class="download-section">
                    <a href="https://www.terabox.app/sharing/link?surl=UMGMUJXYtKUpWfVxvdQ7AA" class="download-button">Try ShortGPT without RAG</a>
                </section>
            </div>
        </div>
        
        <!-- With RAG Dropdown Section -->
        <div class="dropdown">
            <button class="dropdown-toggle with-rag" onclick="toggleDropdown('withRagContent', this)">With RAG</button>
            <div class="dropdown-content" id="withRagContent">
                <header class="header">
                    <p>ShortGPT with Retrieval Augmented Generation (RAG) enhances the core model with real-time document retrieval capabilities. This approach allows the model to access and leverage external knowledge during inference.</p>
                </header>
                
                <section class="features">
                    <div class="feature-card">
                        <h3>Knowledge Integration</h3>
                        <p>Seamlessly incorporate PDFs, Wikipedia articles, and other text sources into a unified knowledge base.</p>
                    </div>
                    <div class="feature-card">
                        <h3>Efficient Storage</h3>
                        <p>Dual-format storage with JSON for metadata and PyTorch tensors for vector embeddings enables fast retrieval.</p>
                    </div>
                    <div class="feature-card">
                        <h3>Batch Processing</h3>
                        <p>Memory-efficient handling of large datasets through incremental batch processing and smart caching.</p>
                    </div>
                    <div class="feature-card">
                        <h3>System Requirements</h3>
                        <ul>
                            <li>CPU: Intel Core i7 or AMD Ryzen 7</li>
                            <li>RAM: 16GB minimum, 32GB recommended</li>
                            <li>GPU: NVIDIA with 4GB+ VRAM for acceleration</li>
                        </ul>
                    </div>
                    <div class="feature-card">
                        <h3>Performance Metrics</h3>
                        <ul>
                            <li>3.5M tokens processed per minute on GPU</li>
                            <li>Retrieval latency under 50ms for 100K chunks</li>
                            <li>98% accuracy on benchmark QA datasets</li>
                        </ul>
                    </div>
                    <div class="feature-card">
                        <h3>Custom Training</h3>
                        <p>Train the model with your specific knowledge like (pdf,txt) and get responses from model.</p>
                    </div>
                    <div class="feature-card">
                        <h3>Hardware Support</h3>
                        <p>Optimized for both GPU and CPU environments, providing flexible deployment options.</p>
                    </div>
                    <div class="feature-card">
                        <h3>Advanced Architecture</h3>
                        <p>Built with custom transformers, attention layers, and positional encoders for optimal performance.</p>
                    </div>
                </section>

                <h2>RAG Architecture Components</h2>
                <br>
                <table style="width: 100%; border-collapse: collapse; border: 1px solid #ddd; font-family: Arial, sans-serif;">
                    <thead>
                        <tr>
                            <th>Component/Algorithm</th>
                            <th>Description</th>
                            <th>Benefit</th>
                        </tr>
                    </thead>
                    <tbody>
                        <!-- Original algorithm features -->
                        <tr>
                            <td><b>Transformer</b></td>
                            <td>Replaces RNNs with self-attention</td>
                            <td>Fast parallel processing</td>
                        </tr>
                        <tr>
                            <td><b>Multi-Head Self-Attention (8 heads)</b></td>
                            <td>Learns multiple relationships in parallel</td>
                            <td>Improves context understanding</td>
                        </tr>
                        <tr>
                            <td><b>512-Dimension Embeddings</b></td>
                            <td>Represents tokens with high-dimensional vectors</td>
                            <td>Captures complex meanings</td>
                        </tr>
                        <tr>
                            <td><b>2048-Dimension Feed-Forward Layer</b></td>
                            <td>Expands and compresses attention output</td>
                            <td>Enhances feature extraction</td>
                        </tr>
                        <tr>
                            <td><b>Word-Level Tokenization</b></td>
                            <td>Uses full words instead of subwords</td>
                            <td>Simplifies processing, useful for short texts</td>
                        </tr>
                        <tr>
                            <td><b>Frequency-Based Vocabulary Truncation</b></td>
                            <td>Keeps only high-frequency words</td>
                            <td>Reduces memory usage and speeds up inference</td>
                        </tr>
                        
                        <!-- Data Storage -->
                        <tr>
                            <td><b>knowledge.json</b></td>
                            <td>Storage for text chunks, source metadata, and chunk IDs</td>
                            <td>Organizes textual data with context information</td>
                        </tr>
                        <tr>
                            <td><b>embeddings.pt</b></td>
                            <td>PyTorch tensor with vector representations aligned with chunks</td>
                            <td>Enables fast similarity search for retrieval</td>
                        </tr>
                        
                        <!-- Base Training -->
                        <tr>
                            <td><b>process_pdf()</b></td>
                            <td>Extracts text from PDF and creates chunks with metadata</td>
                            <td>Prepares documents for embedding and retrieval</td>
                        </tr>
                        <tr>
                            <td><b>compute_embeddings()</b></td>
                            <td>Converts text to vectors using embedding model</td>
                            <td>Creates semantic representations for chunks</td>
                        </tr>
                        <tr>
                            <td><b>save()</b></td>
                            <td>Saves chunks, sources, and tensor embeddings to disk</td>
                            <td>Persists knowledge base for future use</td>
                        </tr>
                        <tr>
                            <td><b>load()</b></td>
                            <td>Loads knowledge.json and embeddings.pt into memory</td>
                            <td>Prepares knowledge base for querying</td>
                        </tr>
                        
                        <!-- Training New Data -->
                        <tr>
                            <td><b>extend_knowledge_base()</b></td>
                            <td>Copies original chunks and clones original embeddings</td>
                            <td>Preserves existing data while preparing for extension</td>
                        </tr>
                        <tr>
                            <td><b>Merge knowledge</b></td>
                            <td>Processes new PDFs, computes embeddings, concatenates with original</td>
                            <td>Integrates new information with existing knowledge</td>
                        </tr>
                        
                        <!-- Wikipedia Integration -->
                        <tr>
                            <td><b>Process in batches</b></td>
                            <td>Gets Wikipedia articles, chunks text, tracks batch size</td>
                            <td>Manages memory usage for large corpus processing</td>
                        </tr>
                        <tr>
                            <td><b>update_embeddings_with_batch()</b></td>
                            <td>Computes embeddings for current batch and merges with existing data</td>
                            <td>Allows incremental updates to knowledge base</td>
                        </tr>
                        
                        <!-- Retrieval -->
                        <tr>
                            <td><b>load_knowledge_base()</b></td>
                            <td>Loads knowledge.json to memory and embeddings.pt to GPU memory</td>
                            <td>Optimizes retrieval performance with GPU acceleration</td>
                        </tr>
                        <tr>
                            <td><b>cosine_similarity()</b></td>
                            <td>Compares query embedding with chunk embeddings</td>
                            <td>Identifies most relevant chunks for response generation</td>
                        </tr>
                        <tr>
                            <td><b>torch.cat()</b></td>
                            <td>Concatenates original and new embeddings tensors</td>
                            <td>Efficiently merges vector representations</td>
                        </tr>
                        <tr>
                            <td><b>CPU/GPU Memory Management</b></td>
                            <td>Strategically moves tensors between CPU and GPU memory</td>
                            <td>Balances performance and memory constraints</td>
                        </tr>
                    </tbody>
                </table>
                <section class="architecture-section">
                    <h2>RAG Workflow</h2>
                    <div class="architecture-grid">
                        <div class="feature-card">
                            <h3>1. Data Storage Structure</h3>
                            <p>The system uses knowledge.json for storing text chunks with metadata and embeddings.pt for vector representations in PyTorch format.</p>
                        </div>
                        <div class="feature-card">
                            <h3>2. PDF Processing</h3>
                            <p>Documents are extracted, chunked, and associated with metadata through the process_pdf() function for structured knowledge representation.</p>
                        </div>
                        <div class="feature-card">
                            <h3>3. Embedding Computation</h3>
                            <p>Text chunks are transformed into 512-dimensional vector embeddings capturing semantic meaning for effective retrieval operations.</p>
                        </div>
                        <div class="feature-card">
                            <h3>4. Knowledge Extension</h3>
                            <p>The system can incorporate new documents while preserving original data through careful copying and tensor concatenation operations.</p>
                        </div>
                        <div class="feature-card">
                            <h3>5. Web Knowledge Integration</h3>
                            <p>Wikipedia articles are processed in manageable batches to enrich the knowledge base while maintaining memory efficiency.</p>
                        </div>
                        <div class="feature-card">
                            <h3>6. GPU-Accelerated Retrieval</h3>
                            <p>Cosine similarity between query and chunk embeddings leverages GPU processing for fast and accurate information retrieval.</p>
                        </div>
                        <div class="feature-card">
                            <h3>7. Multi-Head Attention</h3>
                            <p>The system employs 8-head self-attention mechanisms to learn multiple relationship patterns in parallel across text data.</p>
                        </div>
                        <div class="feature-card">
                            <h3>8. Feed-Forward Processing</h3>
                            <p>A 2048-dimension feed-forward layer expands and compresses attention output for enhanced feature extraction capabilities.</p>
                        </div>
                        <div class="feature-card">
                            <h3>9. Tokenization Strategy</h3>
                            <p>Word-level tokenization simplifies processing for short texts while frequency-based vocabulary truncation optimizes memory usage.</p>
                        </div>
                    </div>
                    <br>
                    <h2>Model Architecture</h2>
                    <div class="architecture-grid">
                        <img src="./images/project1/rag_complete_working_diagram.png" class="architecture-image" alt="training results image" onclick="openModal(this)" alt="Training Results">
                        <img src="./images/project1/rag_detail.png" class="architecture-image" alt="compiler output image" onclick="openModal(this)" alt="Compiler Output">
                    </div>
                </section>

                <section class="architecture-section">
                    <h2>Results</h2>
                    <div class="architecture-grid">
                        <img src="./images/project1/rag1.png" class="architecture-image" alt="training results image" onclick="openModal(this)" alt="Training Results">
                        <img src="./images/project1/rag3.png" class="architecture-image" alt="training results image" onclick="openModal(this)" alt="Training Results">
                        <img src="./images/project1/rag4.png" class="architecture-image" alt="compiler output image" onclick="openModal(this)" alt="Compiler Output">
                        <img src="./images/project1/rag5.png" class="architecture-image" alt="training results image" onclick="openModal(this)" alt="Training Results">
                        <img src="./images/project1/rag6.png" class="architecture-image" alt="compiler output image" onclick="openModal(this)" alt="Compiler Output">
                        <img src="./images/project1/rag7.png" class="architecture-image" alt="compiler output image" onclick="openModal(this)" alt="Compiler Output">
                    </div>
                </section>
                <section class="architecture-section">
                    <h2 style="font-size: 50px; font-weight: bold;">Verifying whether the text was generated by AI or a human!</h2>
                    <br>
                    <img src="./images/project1/rag2.png" class="architecture-image" alt="compiler output image" onclick="openModal(this)" alt="Compiler Output">
                    <br>
                    <br>
                    <h1 style="font-size: 30px; font-weight: bold;">Different AI models</h1>
                    <br>
                    <h4 style="font-family: 'Courier New', monospace;font-weight: lighter; ">We conducted an in-depth comparison of <span style="border-bottom: 4px solid orange;">ShortGPT</span> with leading AI models, including ChatGPT, Deep Seek, ClaudeAI, Cohere, Gemma, Grok, Meta, and Mistral, to evaluate their AI-generated content. Our analysis revealed that ChatGPT, Deep Seek, ClaudeAI, Cohere, Gemma, Meta, and Mistral consist of 100% AI-generated text, while Grok contains 59% AI-generated text. Interestingly, <span style="border-bottom: 4px solid orange;">ShortGPT was found to contain 0% AI-generated text</span>, demonstrating its unique approach to processing and generating information. This comparison highlights the distinctiveness of ShortGPT and its potential to offer a new paradigm in AI development. Explore the detailed architecture documents below.My <span style="border-bottom: 4px solid orange;">ShortGPT</span> model achieves 100% humanization, outperforming other models in generating natural, human-like text.</h4>
                    <br>
                    <br>
                    <div class="architecture-grid">
                        <div>
                            <embed  src="./Checking text/chatGPT.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• ChatGPT</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/deep_seek.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• Deep Seek</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/claude.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• ClaudeAI</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/cohere.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• Cohere</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/gemma.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• Gemma</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/grok.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• Grok</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/meta.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• Meta</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/mistral.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• Mistral</h1>
                        </div>
                        <div>
                            <embed  src="./Checking text/my_model.pdf" class="architecture-image" width="300px" height="500px"/>
                            <h1>‚û• ShortGPT</h1>
                        </div>
                    </div>
                </section>
                <h3>"The RAG-enhanced ShortGPT model creates a perfect balance between fixed, trained knowledge and dynamic, document-based retrieval. This hybrid approach gives you the best of both worlds."</h3>
                <h3>Coming soon: Advanced filtering capabilities and multi-modal document support!</h3>
                <br>
                <h3>"Experience the power of on-demand knowledge without sacrificing the performance of a finely-tuned model."</h3>
                <br>
                <section class="download-section">
                    <a href="https://github.com/hemanthreddykunduru/mini_RAG" class="download-button">Try ShortGPT with RAG</a>
                </section>
            </div>
        </div>
    </div>

    <script>
        var modal = document.getElementById("imageModal");
        var modalImg = document.getElementById("modalImage");
        var closeBtn = document.getElementsByClassName("close")[0];

        function openModal(img) {
            modal.style.display = "block";
            modalImg.src = img.src;
        }

        closeBtn.onclick = function() {
            modal.style.display = "none";
        }

        modal.onclick = function(event) {
            if (event.target === modal) {
                modal.style.display = "none";
            }
        }

        document.addEventListener('keydown', function(event) {
            if (event.key === "Escape") {
                modal.style.display = "none";
            }
        });

    function toggleDropdown(contentId, button) {
        const content = document.getElementById(contentId);
        content.classList.toggle("show");
        button.classList.toggle("active");
    }
    </script>
</body>
</html>
